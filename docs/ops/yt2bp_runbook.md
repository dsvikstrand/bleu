# YT2BP Runbook

## Purpose and ownership
- Service: YouTube to Blueprint (`/api/youtube-to-blueprint`)
- Runtime host: Oracle (`oracle-free`)
- Service unit: `agentic-backend.service`
- Primary owner: app backend maintainers

## bleuV1 source-first integration context
- YT2BP remains the ingestion/generation entrypoint only.
- Personal-first routing is now expected:
  - generated draft is saved to `My Feed` (`user_feed_items.state = my_feed_published`).
  - channel visibility is handled by auto-channel pipeline when enabled.
  - `/youtube` runs core generation first and executes optional review/banner asynchronously after core success.
  - `Save to My Feed` is non-blocking while optional review/banner complete and attach later.
  - banner prompts are visual-only by policy (no readable text/typography/logos/watermarks).
- Gate runtime mode:
  - legacy manual candidate flow uses `CHANNEL_GATES_MODE` (`bypass|shadow|enforce`).
  - auto-channel flow uses `AUTO_CHANNEL_GATE_MODE` (`enforce` default recommendation).
- Legacy candidate lifecycle endpoints (same backend service, rollback path):
  - `POST /api/channel-candidates`
  - `GET /api/channel-candidates/:id`
  - `POST /api/channel-candidates/:id/evaluate`
  - `POST /api/channel-candidates/:id/publish`
  - `POST /api/channel-candidates/:id/reject`
- Auto-channel endpoint:
  - `POST /api/my-feed/items/:id/auto-publish`
- Profile feed read endpoint:
  - `GET /api/profile/:userId/feed` (optional auth; public profiles readable, private profiles owner-only)

## Health checks
- Local service health:
```bash
ssh oracle-free 'curl -sS http://localhost:8787/api/health'
```
- Public health:
```bash
curl -sS https://bapi.vdsai.cloud/api/health
```
- Latest ingestion job (service auth):
```bash
curl -sS https://bapi.vdsai.cloud/api/ingestion/jobs/latest \
  -H "x-service-token: $INGESTION_SERVICE_TOKEN"
```
- Latest auto-banner queue snapshot (service auth):
```bash
curl -sS https://bapi.vdsai.cloud/api/auto-banner/jobs/latest \
  -H "x-service-token: $INGESTION_SERVICE_TOKEN"
```
- Public YT2BP endpoint basic probe:
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/youtube-to-blueprint \
  -H 'Content-Type: application/json' \
  --data '{"video_url":"https://www.youtube.com/watch?v=16hFQZbxZpU","generate_review":false,"generate_banner":false,"source":"youtube_mvp"}'
```

## Service lifecycle
- Status:
```bash
ssh oracle-free 'sudo systemctl status --no-pager agentic-backend.service'
```
- Restart:
```bash
ssh oracle-free 'sudo systemctl restart agentic-backend.service'
```
- Tail logs:
```bash
ssh oracle-free 'sudo journalctl -u agentic-backend.service -n 200 --no-pager'
```
- Pull + restart:
```bash
ssh oracle-free 'cd /home/ubuntu/remix-of-stackwise-advisor && git pull --ff-only && sudo systemctl restart agentic-backend.service'
```

## Environment checklist
Required runtime variables:
- `OPENAI_API_KEY`
- `YOUTUBE_DATA_API_KEY` (required for `/api/youtube-search`)
- `TRANSCRIPT_PROVIDER` (`yt_to_text` or `youtube_timedtext`)
- `YT2BP_ENABLED`
- `YT2BP_QUALITY_ENABLED`
- `YT2BP_CONTENT_SAFETY_ENABLED`
- `YT2BP_ANON_LIMIT_PER_MIN`
- `YT2BP_AUTH_LIMIT_PER_MIN`
- `YT2BP_IP_LIMIT_PER_HOUR`
- `YT2BP_CORE_TIMEOUT_MS` (default `120000`)
- `CHANNEL_GATES_MODE` (`bypass` | `shadow` | `enforce`)
- `AUTO_CHANNEL_PIPELINE_ENABLED` (`true|false`)
- `AUTO_CHANNEL_DEFAULT_SLUG` (default `general`)
- `AUTO_CHANNEL_CLASSIFIER_MODE` (`deterministic_v1|llm_labeler_v1|general_placeholder`)
- `AUTO_CHANNEL_FALLBACK_SLUG` (default `general`)
- `AUTO_CHANNEL_GATE_MODE` (`bypass|shadow|enforce`)
- `AUTO_CHANNEL_LEGACY_MANUAL_FLOW_ENABLED` (`true` default)
- `SUPABASE_SERVICE_ROLE_KEY` (required for cron ingestion trigger path)
- `INGESTION_SERVICE_TOKEN` (shared secret for `/api/ingestion/jobs/trigger`)
- `ENABLE_DEBUG_ENDPOINTS` (`false` by default; must be `true` to enable debug simulation endpoint)
- `INGESTION_MAX_PER_SUBSCRIPTION` (default `5`)
- `REFRESH_SCAN_COOLDOWN_MS` (default `30000`)
- `REFRESH_GENERATE_COOLDOWN_MS` (default `120000`)
- `REFRESH_GENERATE_MAX_ITEMS` (default `20`)
- `REFRESH_FAILURE_COOLDOWN_HOURS` (default `6`)
- `INGESTION_STALE_RUNNING_MS` (default `1800000`)
- `SUBSCRIPTION_AUTO_BANNER_MODE` (`off|async|sync`)
- `SUBSCRIPTION_AUTO_BANNER_CAP` (default `1000`)
- `SUBSCRIPTION_AUTO_BANNER_MAX_ATTEMPTS` (default `3`)
- `SUBSCRIPTION_AUTO_BANNER_TIMEOUT_MS` (default `12000`)
- `SUBSCRIPTION_AUTO_BANNER_BATCH_SIZE` (default `20`)
- `SUBSCRIPTION_AUTO_BANNER_CONCURRENCY` (default `1`)
- `AUTO_BANNER_STALE_RUNNING_MS` (default `1200000`)

Safe defaults:
- `YT2BP_ENABLED=true`
- `YT2BP_QUALITY_ENABLED=true`
- `YT2BP_CONTENT_SAFETY_ENABLED=true`
- `YT2BP_ANON_LIMIT_PER_MIN=6`
- `YT2BP_AUTH_LIMIT_PER_MIN=20`
- `YT2BP_IP_LIMIT_PER_HOUR=30`
- `YT2BP_CORE_TIMEOUT_MS=120000`
- `CHANNEL_GATES_MODE=bypass`
- `AUTO_CHANNEL_PIPELINE_ENABLED=false`
- `AUTO_CHANNEL_DEFAULT_SLUG=general`
- `AUTO_CHANNEL_CLASSIFIER_MODE=deterministic_v1`
- `AUTO_CHANNEL_FALLBACK_SLUG=general`
- `AUTO_CHANNEL_GATE_MODE=enforce`
- `AUTO_CHANNEL_LEGACY_MANUAL_FLOW_ENABLED=true`
- `ENABLE_DEBUG_ENDPOINTS=false`
- `INGESTION_MAX_PER_SUBSCRIPTION=5`
- `REFRESH_SCAN_COOLDOWN_MS=30000`
- `REFRESH_GENERATE_COOLDOWN_MS=120000`
- `REFRESH_GENERATE_MAX_ITEMS=20`
- `REFRESH_FAILURE_COOLDOWN_HOURS=6`
- `INGESTION_STALE_RUNNING_MS=1800000`
- `SUBSCRIPTION_AUTO_BANNER_MODE=off`
- `SUBSCRIPTION_AUTO_BANNER_CAP=1000`
- `SUBSCRIPTION_AUTO_BANNER_MAX_ATTEMPTS=3`
- `SUBSCRIPTION_AUTO_BANNER_TIMEOUT_MS=12000`
- `SUBSCRIPTION_AUTO_BANNER_BATCH_SIZE=20`
- `SUBSCRIPTION_AUTO_BANNER_CONCURRENCY=1`
- `AUTO_BANNER_STALE_RUNNING_MS=1200000`

## Failure playbooks

### `PROVIDER_FAIL`
- Meaning: transcript provider failed upstream.
- Action:
  1) Confirm provider setting (`TRANSCRIPT_PROVIDER`).
  2) Run toy transcript probe:
  ```bash
  TRANSCRIPT_PROVIDER=yt_to_text node --import tsx scripts/toy_fetch_transcript.ts --url 'https://www.youtube.com/watch?v=16hFQZbxZpU'
  ```
  3) Switch provider if needed.

### `RATE_LIMITED`
- Meaning: anon/auth/hourly limiter tripped.
- Action:
  1) Check request volume in logs.
  2) Temporarily raise limits if operationally justified.
  3) Keep hourly cap as abuse guard.

### `TIMEOUT`
- Meaning: pipeline exceeded max timeout.
- Action:
  1) Confirm `YT2BP_CORE_TIMEOUT_MS` value is sane for current load.
  2) Keep `/youtube` in core-first mode (review/banner async) for user flows.
  3) Validate transcript provider latency.
  4) Check OpenAI latency and retries.

### `SAFETY_BLOCKED`
- Meaning: generated output violated content safety policy.
- Action:
  1) Confirm expected for source video category.
  2) Inspect `yt2bp-content-safety` log lines for flagged criteria.
  3) Do not bypass by default; only tune policy with explicit decision.

### `GENERATION_FAIL`
- Meaning: generation/quality stage failed after retries.
- Action:
  1) Inspect `yt2bp-quality` logs for failing criteria.
  2) Verify `OPENAI_API_KEY` and model availability.
  3) If incident pressure: use fallback profile below.

### `JOB_ALREADY_RUNNING`
- Meaning: a manual refresh generation job is already active for this user.
- Action:
  1) Use `GET /api/ingestion/jobs/<job_id>` (user auth) to track completion.
  2) Wait for terminal state (`succeeded|failed`) before launching a new refresh-generate run.
  3) If job appears stuck, inspect stale recovery settings (`INGESTION_STALE_RUNNING_MS`).

### `candidate_pending_manual_review` growth
- Meaning: gate pipeline is producing warn outcomes (fit/quality) and routing to manual review.
- Action:
  0) Confirm runtime mode first (`CHANNEL_GATES_MODE`).
     - if `bypass`, this state should be rare/unexpected and likely indicates fallback/no-backend path.
     - if `enforce`, continue with the checks below.
  1) Inspect `channel_gate_decisions` for dominant `reason_code`.
  2) Verify candidate inputs (channel slug, tags, step_count) are mapped correctly.
  3) If noisy channel-fit warns dominate, tune fit policy before enabling broader auto paths.

### Misclassification / too many `general` publishes
- Meaning: channel labeling is falling back too often or classifier signal quality dropped.
- Action:
  1) Verify classifier env: `AUTO_CHANNEL_CLASSIFIER_MODE` is expected for this rollout (`deterministic_v1` or `llm_labeler_v1`).
  2) Verify fallback slug is valid: `AUTO_CHANNEL_FALLBACK_SLUG=general` (or another curated slug that exists).
  3) Inspect auto-publish response/log metadata (`classifier_reason`) to split:
     - deterministic mode: `tag_match|alias_match|fallback_general`
     - llm mode: `llm_valid|llm_retry_valid|fallback_general`
  4) If emergency rollback needed, temporarily set `AUTO_CHANNEL_CLASSIFIER_MODE=general_placeholder`.

### `channel_rejected` spike
- Meaning: block outcomes (safety/PII/quality) are increasing and channel publish throughput drops.
- Action:
  0) Confirm runtime mode first (`CHANNEL_GATES_MODE`).
     - in `bypass`, reject spikes should come from explicit manual reject paths, not automated gate blocks.
  1) Inspect `channel_gate_decisions.reason_code` distribution.
  2) Confirm reject path is preserving personal visibility (My Feed should remain visible).
  3) Escalate only after checking for source-content drift (e.g., different incoming topic mix).

## Rollback / fallback controls
Incident profile (temporary):
- Keep endpoint up, reduce strictness first:
  - `YT2BP_QUALITY_ENABLED=false`
  - `YT2BP_CONTENT_SAFETY_ENABLED=true`
- If provider instability dominates:
  - keep endpoint enabled but switch transcript provider.
- Full stop (hard off):
  - `YT2BP_ENABLED=false`

After env change:
```bash
ssh oracle-free 'sudo systemctl restart agentic-backend.service'
```

## Post-deploy confidence checks
- Repro smoke:
```bash
npm run smoke:yt2bp -- --base-url https://bapi.vdsai.cloud
```
- Metrics summary (Oracle logs):
```bash
ssh oracle-free 'cd /home/ubuntu/remix-of-stackwise-advisor && npm run metrics:yt2bp -- --source journalctl --json'
```

## Candidate lifecycle smoke (auth required)
Use a valid bearer token and existing `user_feed_item_id`.
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/channel-candidates \
  -H "Authorization: Bearer $TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{"user_feed_item_id":"<uuid>","channel_slug":"skincare"}'
```

```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/channel-candidates/<candidate_id>/evaluate \
  -H "Authorization: Bearer $TOKEN" \
  -H 'Content-Type: application/json'
```

## Subscription + ingestion smoke
YouTube search smoke (auth required):
```bash
curl -sS "https://bapi.vdsai.cloud/api/youtube-search?q=skincare%202026%20best&limit=10" \
  -H "Authorization: Bearer $TOKEN"
```

YouTube channel search smoke (auth required):
```bash
curl -sS "https://bapi.vdsai.cloud/api/youtube-channel-search?q=skincare%20doctor&limit=10" \
  -H "Authorization: Bearer $TOKEN"
```

Create a subscription (MVP auto-only behavior):
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/source-subscriptions \
  -H "Authorization: Bearer $TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{"channel_input":"https://www.youtube.com/@AliAbdaal"}'
```
Expected behavior:
- first subscribe sets checkpoint only (no old-video prefill).
- one `subscription_notice` feed item is inserted for this user/channel.
- future uploads are ingested automatically.
- subscription rows returned by `GET /api/source-subscriptions` may include `source_channel_avatar_url` (read-time enrichment from YouTube API).
- `subscription_notice` source metadata may include `channel_banner_url` for notice-card backgrounds.
- unsubscribing (`DELETE /api/source-subscriptions/:id`) removes the user-scoped notice card from My Feed for that channel.
- subscription auto-ingest generation runs with review enabled and banner disabled by default.

Manual refresh scan (auth required):
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/source-subscriptions/refresh-scan \
  -H "Authorization: Bearer $TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{"max_per_subscription":5,"max_total":50}'
```
Expected behavior:
- response includes candidate rows and `cooldown_filtered` count (failed items hidden during retry cooldown).
- rate-limited retries return `RATE_LIMITED`.

Manual refresh enqueue (auth required):
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/source-subscriptions/refresh-generate \
  -H "Authorization: Bearer $TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{"items":[{"subscription_id":"<uuid>","source_channel_id":"<channel_id>","video_id":"<video_id>","video_url":"https://www.youtube.com/watch?v=<video_id>","title":"<title>"}]}'
```
Expected behavior:
- request returns quickly with `job_id` and `queued_count`
- generation continues asynchronously in background
- progress is visible via `ingestion_jobs` (scope `manual_refresh_selection`) and resulting My Feed inserts
- successful generation advances subscription checkpoint forward (`last_seen_published_at` / `last_seen_video_id`) for touched subscriptions
- route guardrails:
  - max selected items per run = `20` (`MAX_ITEMS_EXCEEDED`)
  - one active manual refresh job per user (`JOB_ALREADY_RUNNING`)
  - per-user cooldown (`REFRESH_GENERATE_COOLDOWN_MS`)

Manual refresh job status (user auth):
```bash
curl -sS https://bapi.vdsai.cloud/api/ingestion/jobs/<job_id> \
  -H "Authorization: Bearer $TOKEN"
```

Latest manual refresh job for current user (user auth):
```bash
curl -sS "https://bapi.vdsai.cloud/api/ingestion/jobs/latest-mine?scope=manual_refresh_selection" \
  -H "Authorization: Bearer $TOKEN"
```

User-triggered sync (operator/debug path):
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/source-subscriptions/<subscription_id>/sync \
  -H "Authorization: Bearer $TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{}'
```

Service cron trigger:
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/ingestion/jobs/trigger \
  -H "x-service-token: $INGESTION_SERVICE_TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{}'
```

Latest ingestion job snapshot:
```bash
curl -sS https://bapi.vdsai.cloud/api/ingestion/jobs/latest \
  -H "x-service-token: $INGESTION_SERVICE_TOKEN"
```

Staleness guidance:
- If latest `finished_at` is older than 90 minutes, treat ingestion as delayed and start triage.
- If latest `status` is `failed` or `error_code` is `PARTIAL_FAILURE`, inspect per-subscription `last_sync_error`.
- If latest endpoint reports no jobs, verify Oracle cron registration first.

Debug simulation trigger (single subscription, non-prod only):
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/debug/subscriptions/<subscription_id>/simulate-new-uploads \
  -H "x-service-token: $INGESTION_SERVICE_TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{"rewind_days":30}'
```
Notes:
- endpoint returns `404` unless `ENABLE_DEBUG_ENDPOINTS=true`.
- endpoint uses service-token auth only; do not send/require a user bearer token.
- endpoint rewinds checkpoint for one subscription, then runs one sync cycle.
- this can generate blueprints and consume tokens/credits.
- if `SUBSCRIPTION_AUTO_BANNER_MODE=async`, generated blueprints will enqueue banner jobs for background processing.

Auto-banner worker trigger (service auth):
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/auto-banner/jobs/trigger \
  -H "x-service-token: $INGESTION_SERVICE_TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{}'
```

Subscription input note:
- Handle URLs may resolve via `browseId` fallback parsing when direct `channelId` metadata is absent in YouTube page HTML.

Pending card actions (compatibility path for legacy pending items):
```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/my-feed/items/<user_feed_item_id>/accept \
  -H "Authorization: Bearer $TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{}'
```

```bash
curl -sS -X POST https://bapi.vdsai.cloud/api/my-feed/items/<user_feed_item_id>/skip \
  -H "Authorization: Bearer $TOKEN" \
  -H 'Content-Type: application/json' \
  --data '{}'
```

## Oracle cron setup
Example cron entry:
```bash
*/30 * * * * curl -sS -X POST https://bapi.vdsai.cloud/api/ingestion/jobs/trigger -H \"x-service-token: ${INGESTION_SERVICE_TOKEN}\" -H 'Content-Type: application/json' --data '{}' >> /var/log/bleuv1-ingestion-cron.log 2>&1
```

Auto-banner worker cron example (every 5 minutes):
```bash
*/5 * * * * curl -sS -X POST https://bapi.vdsai.cloud/api/auto-banner/jobs/trigger -H \"x-service-token: ${INGESTION_SERVICE_TOKEN}\" -H 'Content-Type: application/json' --data '{}' >> /var/log/bleuv1-auto-banner-cron.log 2>&1
```

## Ingestion reliability triage
1. Confirm cron is running and writing logs:
```bash
ssh oracle-free 'sudo crontab -l | grep ingestion/jobs/trigger'
ssh oracle-free 'tail -n 100 /var/log/bleuv1-ingestion-cron.log'
```
2. Check latest ingestion snapshot:
```bash
curl -sS https://bapi.vdsai.cloud/api/ingestion/jobs/latest -H "x-service-token: $INGESTION_SERVICE_TOKEN"
```
3. If delayed/failed, inspect backend logs:
```bash
ssh oracle-free 'sudo journalctl -u agentic-backend.service -n 200 --no-pager'
```
4. Spot-check subscription rows in app UI (`/subscriptions`) via `Sync issue`, `Last polled`, and health detail text.

## Traceability keys and expected logs
Required IDs for triage:
- `run_id`
- `source_item_id`
- `user_feed_item_id`
- `candidate_id`
- `channel_slug`
- `reason_code` (when applicable)

Expected structured server log markers:
- `[candidate_gate_result]`
- `[candidate_manual_review_pending]`
- `[candidate_published]`
- `[candidate_rejected]`

Useful `mvp_events.event_name` chain for YT2BP split flow:
- `source_pull_requested`
- `source_pull_succeeded`
- `youtube_review_started|youtube_review_succeeded|youtube_review_failed`
- `youtube_banner_started|youtube_banner_succeeded|youtube_banner_failed`
- `my_feed_publish_succeeded`
- `candidate_submitted`
- `candidate_gate_result`
- `channel_publish_succeeded|channel_publish_rejected`
